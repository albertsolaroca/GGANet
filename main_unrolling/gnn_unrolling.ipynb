{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:1o984j3h) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced <strong style=\"color:#cdcd00\">deep-tree-391</strong>: <a href=\"https://wandb.ai/albert-sola9/Unrolling%20WDNs/runs/1o984j3h\" target=\"_blank\">https://wandb.ai/albert-sola9/Unrolling%20WDNs/runs/1o984j3h</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>.\\wandb\\run-20230516_122616-1o984j3h\\logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:1o984j3h). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333327028, max=1.0â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24de8356fef44a2292dcb379c4e46901"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.15.2 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.13.7"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>C:\\Code\\main_unrolling\\wandb\\run-20230516_140111-uf07e7y5</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href=\"https://wandb.ai/albert-sola9/Unrolling%20WDNs/runs/uf07e7y5\" target=\"_blank\">ruby-violet-392</a></strong> to <a href=\"https://wandb.ai/albert-sola9/Unrolling%20WDNs\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/albert-sola9/Unrolling%20WDNs/runs/uf07e7y5?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x266af56f490>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch_geometric.utils import to_networkx\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv, Sequential\n",
    "import networkx as nx\n",
    "\n",
    "from utils.miscellaneous import read_config\n",
    "from utils.miscellaneous import create_folder_structure_MLPvsGNN\n",
    "from utils.miscellaneous import initalize_random_generators\n",
    "\n",
    "from training.train import training\n",
    "from training.test import testing\n",
    "\n",
    "from utils.visualization import plot_R2, plot_loss\n",
    "\n",
    "wandb.init(project=\"Unrolling WDNs\", entity=\"albert-sola9\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parse configuration file + initializations\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folder: ./experiments/unrolling_GNN_WDN0009\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# read config files\n",
    "cfg = read_config(\"config_unrolling_GNN.yaml\")\n",
    "# create folder for results\n",
    "exp_name = cfg['exp_name']\n",
    "data_folder = cfg['data_folder']\n",
    "results_folder = create_folder_structure_MLPvsGNN(cfg, parent_folder='./experiments')\n",
    "\n",
    "\n",
    "all_wdn_names = cfg['networks']\n",
    "initalize_random_generators(cfg, count=0)\n",
    "\n",
    "# initialize pytorch device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# device ='cpu'\n",
    "print(device)\n",
    "#torch.set_num_threads(12)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# TO DO: at the moment I am not using the parsed values for batch size and num_epochs ;\n",
    "# I am not using alpha as well because the loss has no \"smoothness\" penalty (yet)\n",
    "batch_size = cfg['trainParams']['batch_size']\n",
    "alpha = cfg['lossParams']['alpha']\n",
    "res_columns = ['train_loss', 'valid_loss','test_loss','max_train_loss', 'max_valid_loss','max_test_loss', 'min_train_loss', 'min_valid_loss','min_test_loss','r2_train', 'r2_valid',\n",
    "\t\t\t   'r2_test','total_params','total_time','test_time','num_epochs']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "\n",
    "class PowerLogTransformer(BaseEstimator,TransformerMixin):\n",
    "\tdef __init__(self,log_transform=False,power=4,reverse=True):\n",
    "\t\tif log_transform == True:\n",
    "\t\t\tself.log_transform = log_transform\n",
    "\t\t\tself.power = None\n",
    "\t\telse:\n",
    "\t\t\tself.power = power\n",
    "\t\t\tself.log_transform = None\n",
    "\t\tself.reverse=reverse\n",
    "\t\tself.max_ = None\n",
    "\t\tself.min_ = None\n",
    "\n",
    "\tdef fit(self,X,y=None):\n",
    "\t\tself.max_ = np.max(X)\n",
    "\t\tself.min_ = np.min(X)\n",
    "\t\treturn self\n",
    "\n",
    "\tdef transform(self,X):\n",
    "\t\tif self.log_transform==True:\n",
    "\t\t\tif self.reverse == True:\n",
    "\t\t\t\treturn np.log1p(self.max_-X)\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn np.log1p(X-self.min_)\n",
    "\t\telse:\n",
    "\t\t\tif self.reverse == True:\n",
    "\t\t\t\treturn (self.max_-X)**(1/self.power )\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn (X-self.min_)**(1/self.power )\n",
    "\n",
    "\tdef inverse_transform(self,X):\n",
    "\t\tif self.log_transform==True:\n",
    "\t\t\tif self.reverse == True:\n",
    "\t\t\t\treturn (self.max_ - np.exp(X))\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn (np.exp(X) + self.min_)\n",
    "\t\telse:\n",
    "\t\t\tif self.reverse == True:\n",
    "\t\t\t\treturn (self.max_ - X**self.power )\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn (X**self.power + self.min_)\n",
    "\n",
    "class GraphNormalizer:\n",
    "\tdef __init__(self, x_feat_names=['elevation','base_demand','base_head'],\n",
    "\t\t\t\t ea_feat_names=['diameter','length','roughness'], output='pressure'):\n",
    "\t\t# store\n",
    "\t\tself.x_feat_names = x_feat_names\n",
    "\t\tself.ea_feat_names = ea_feat_names\n",
    "\t\tself.output = output\n",
    "\n",
    "\t\t# create separate scaler for each feature (can be improved, e.g., you can fit a scaler for multiple columns)\n",
    "\t\tself.scalers = {}\n",
    "\t\tfor feat in self.x_feat_names:\n",
    "\t\t\tif feat == 'elevation':\n",
    "\t\t\t\tself.scalers[feat] = PowerLogTransformer(log_transform=True,reverse=False)\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.scalers[feat] = MinMaxScaler()\n",
    "\t\tself.scalers[output] = PowerLogTransformer(log_transform=True,reverse=True)\n",
    "\t\tfor feat in self.ea_feat_names:\n",
    "\t\t\tif feat == 'length':\n",
    "\t\t\t\tself.scalers[feat] = PowerLogTransformer(log_transform=True,reverse=False)\n",
    "\t\t\telse:\n",
    "\t\t\t\tself.scalers[feat] = MinMaxScaler()\n",
    "\n",
    "\tdef fit(self, graphs):\n",
    "\t\t''' Fit the scalers on an array of x and ea features\n",
    "\t\t'''\n",
    "\t\tx, y, ea = from_graphs_to_pandas(graphs)\n",
    "\t\tfor ix, feat in enumerate(self.x_feat_names):\n",
    "\t\t\tself.scalers[feat] = self.scalers[feat].fit(x[:,ix].reshape(-1,1))\n",
    "\t\tself.scalers[self.output] = self.scalers[self.output].fit(y.reshape(-1,1))\n",
    "\t\tfor ix, feat in enumerate(self.ea_feat_names):\n",
    "\t\t\tself.scalers[feat] = self.scalers[feat].fit(ea[:,ix].reshape(-1,1))\n",
    "\t\treturn self\n",
    "\n",
    "\tdef transform(self, graph):\n",
    "\t\t''' Transform graph based on normalizer\n",
    "\t\t'''\n",
    "\t\tgraph = graph.clone()\n",
    "\t\tfor ix, feat in enumerate(self.x_feat_names):\n",
    "\t\t\ttemp = graph.x[:,ix].numpy().reshape(-1,1)\n",
    "\t\t\tgraph.x[:,ix] = torch.tensor(self.scalers[feat].transform(temp).reshape(-1))\n",
    "\t\tfor ix, feat in enumerate(self.ea_feat_names):\n",
    "\t\t\ttemp = graph.edge_attr[:,ix].numpy().reshape(-1,1)\n",
    "\t\t\tgraph.edge_attr[:,ix] = torch.tensor(self.scalers[feat].transform(temp).reshape(-1))\n",
    "\t\tgraph.y = torch.tensor(self.scalers[self.output].transform(graph.y.numpy().reshape(-1,1)).reshape(-1))\n",
    "\t\treturn graph\n",
    "\n",
    "\tdef inverse_transform(self, graph):\n",
    "\t\t''' Perform inverse transformation to return original features\n",
    "\t\t'''\n",
    "\t\tgraph = graph.clone()\n",
    "\t\tfor ix, feat in enumerate(self.x_feat_names):\n",
    "\t\t\ttemp = graph.x[:,ix].numpy().reshape(-1,1)\n",
    "\t\t\tgraph.x[:,ix] = torch.tensor(self.scalers[feat].inverse_transform(temp).reshape(-1))\n",
    "\t\tfor ix, feat in enumerate(self.ea_feat_names):\n",
    "\t\t\ttemp = graph.edge_attr[:,ix].numpy().reshape(-1,1)\n",
    "\t\t\tgraph.edge_attr[:,ix] = torch.tensor(self.scalers[feat].inverse_transform(temp).reshape(-1))\n",
    "\t\tgraph.y = torch.tensor(self.scalers[self.output].inverse_transform(graph.y.numpy().reshape(-1,1)).reshape(-1))\n",
    "\t\treturn graph\n",
    "\n",
    "\tdef transform_array(self,z,feat_name):\n",
    "\t\t'''\n",
    "\t\t\tThis is for MLP dataset; it can be done better (the entire thing, from raw data to datasets)\n",
    "\t\t'''\n",
    "\t\treturn torch.tensor(self.scalers[feat_name].transform(z).reshape(-1))\n",
    "\n",
    "\tdef inverse_transform_array(self,z,feat_name):\n",
    "\t\t'''\n",
    "\t\t\tThis is for MLP dataset; it can be done better (the entire thing, from raw data to datasets)\n",
    "\t\t'''\n",
    "\t\treturn torch.tensor(self.scalers[feat_name].inverse_transform(z))\n",
    "\n",
    "def from_graphs_to_pandas(graphs, l_x=3, l_ea=3):\n",
    "\tx = []\n",
    "\ty = []\n",
    "\tea = []\n",
    "\tfor i, graph in enumerate(graphs):\n",
    "\t\tx.append(graph.x.numpy())\n",
    "\t\ty.append(graph.y.reshape(-1,1).numpy())\n",
    "\t\tea.append(graph.edge_attr.numpy())\n",
    "\treturn np.concatenate(x,axis=0),np.concatenate(y,axis=0),np.concatenate(ea,axis=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "from models.virtual_nodes import add_virtual_nodes\n",
    "from torch_geometric.utils import to_undirected\n",
    "\n",
    "# constant indexes for node and edge features\n",
    "HEAD_INDEX = 0\n",
    "BASEDEMAND_INDEX = 1\n",
    "TYPE_INDEX = 2\n",
    "DIAMETER_INDEX = 0\n",
    "LENGTH_INDEX = 1\n",
    "ROUGHNESS_INDEX = 2\n",
    "FLOW_INDEX = 3\n",
    "\n",
    "def load_raw_dataset(wdn_name, data_folder):\n",
    "\t'''\n",
    "\tLoad tra/val/data for a water distribution network datasets\n",
    "\t-------\n",
    "\twdn_name : string\n",
    "\t\tprefix of pickle files to open\n",
    "\tdata_folder : string\n",
    "\t\tpath to datasets\n",
    "\t'''\n",
    "\n",
    "\tdata_tra = pickle.load(open(f'{data_folder}/train/{wdn_name}.p', \"rb\"))\n",
    "\tdata_val = pickle.load(open(f'{data_folder}/valid/{wdn_name}.p', \"rb\"))\n",
    "\tdata_tst = pickle.load(open(f'{data_folder}/test/{wdn_name}.p', \"rb\"))\n",
    "\n",
    "\treturn data_tra, data_val, data_tst\n",
    "\n",
    "def create_dataset(database, normalizer=None, HW_rough_minmax=[60, 150],add_virtual_reservoirs=False, output='pressure'):\n",
    "\t'''\n",
    "\tCreates working datasets dataset from the pickle databases\n",
    "\t------\n",
    "\tdatabase : list\n",
    "\t\teach element in the list is a pickle file containing Data objects\n",
    "\tnormalization: dict\n",
    "\t\tnormalize the dataset using mean and std\n",
    "\t'''\n",
    "\t# Roughness info (Hazen-Williams) / TODO: remove the hard_coding\n",
    "\tminR = HW_rough_minmax[0]\n",
    "\tmaxR = HW_rough_minmax[1]\n",
    "\n",
    "\tgraphs = []\n",
    "\n",
    "\tfor i in database:\n",
    "\t\tgraph = torch_geometric.data.Data()\n",
    "\n",
    "\t\t# Node attributes\n",
    "\t\t# elevation_head = i.elevation + i.base_head\n",
    "\t\t# elevation_head = i.elevation.clone()\n",
    "\t\t# elevation_head[elevation_head == 0] = elevation_head.mean()\n",
    "\n",
    "\t\tmin_elevation = min(i.elevation[i.type_1H == 0])\n",
    "\t\thead = i.pressure + i.base_head + i.elevation\n",
    "\t\t# elevation_head[i.type_1H == 1] = head[i.type_1H == 1]\n",
    "\t\t# elevation = elevation_head - min_elevation\n",
    "\n",
    "\t\t# base_demand = i.base_demand * 1000  # convert to l/s\n",
    "\t\t# graph.x = torch.stack((i.elevation, i.base_demand, i.type_1H*i.base_head), dim=1).float()\n",
    "\t\tgraph.x = torch.stack((i.elevation+i.base_head, i.base_demand, i.type_1H), dim=1).float()\n",
    "\t\t# graph.x = torch.stack((i.elevation+i.base_head, i.base_demand, i.type_1H), dim=1).float()\n",
    "\n",
    "\t\t# Position and ID\n",
    "\t\tgraph.pos = i.pos\n",
    "\t\tgraph.ID = i.ID\n",
    "\n",
    "\t\t# Edge index (Adjacency matrix)\n",
    "\t\tgraph.edge_index = i.edge_index\n",
    "\n",
    "\t\t# Edge attributes\n",
    "\t\tdiameter = i.diameter\n",
    "\t\tlength = i.length\n",
    "\t\troughness = i.roughness\n",
    "\t\tgraph.edge_attr = torch.stack((diameter, length, roughness), dim=1).float()\n",
    "\n",
    "\t\t# pressure = i.pressure\n",
    "\t\t# graph.y = pressure.reshape(-1,1)\n",
    "\n",
    "\t\t# Graph output (head)\n",
    "\t\tif output == 'head':\n",
    "\t\t\tgraph.y  = head[i.type_1H == 0].reshape(-1, 1)\n",
    "\t\telse:\n",
    "\t\t\tgraph.y = i.pressure[i.type_1H == 0].reshape(-1, 1)\n",
    "\t\t\t# pressure[i.type_1H == 1] = 0 # THIS HAS TO BE DONE BETTER\n",
    "\t\t\t# graph.y = pressure\n",
    "\n",
    "\n",
    "\t\t# normalization\n",
    "\t\tif normalizer is not None:\n",
    "\t\t\tgraph = normalizer.transform(graph)\n",
    "\n",
    "\t\tif add_virtual_reservoirs:\n",
    "\n",
    "\t\t\tgraph.x = torch.nn.functional.pad(graph.x, (0, 1))\n",
    "\t\t\tgraph.edge_attr = torch.nn.functional.pad(graph.edge_attr, (0, 1))\n",
    "\t\t\tadd_virtual_nodes(graph)\n",
    "\t\tgraphs.append(graph)\n",
    "\tA12 = nx.incidence_matrix(to_networkx(graphs[0]), oriented=True).toarray().transpose()\n",
    "\treturn graphs, A12\n",
    "\n",
    "def create_incidence_matrices(graphs,incidence_matrix):\n",
    "\n",
    "\t# position of reservoirs\n",
    "\n",
    "\tix_res = graphs[0].x[:,TYPE_INDEX].numpy()>0\n",
    "\tix_edge = graphs[0].edge_index.numpy().T\n",
    "\tix_edge = (ix_edge[:, 0] < ix_edge[:, 1])\n",
    "\tincidence_matrix = incidence_matrix[ix_edge,:]\n",
    "\tA10 = incidence_matrix[:, ix_res]\n",
    "\tA12 = incidence_matrix[:, ~ix_res]\n",
    "\tA12[np.where(A10 == 1),:] *= -1\n",
    "\tA10[np.where(A10 == 1),:] *= -1\n",
    "\treturn A10, A12"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "#Unrolling with flows, heads, H0, q and S\n",
    "class UnrollingGNN(nn.Module):\n",
    "\tdef __init__(self, num_outputs, A12, A10, num_blocks, edge_features,node_features):\n",
    "\n",
    "\t\tsuper(UnrollingGNN, self).__init__()\n",
    "\t\ttorch.manual_seed(42)\n",
    "\t\tself.num_blocks = num_blocks\n",
    "\t\tself.node_features = node_features\n",
    "\t\tself.n = 1.852\n",
    "\n",
    "\t\tself.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\t\tself.A12 = torch.from_numpy(A12).to(self.device)\n",
    "\t\tself.num_heads = self.A12.shape[1]\n",
    "\t\tself.num_flows = self.A12.shape[0]\n",
    "\t\tself.A10 = torch.from_numpy(A10).to(self.device)\n",
    "\n",
    "\t\tself.message_passings = nn.ModuleList()\n",
    "\n",
    "\t\tfor i in range(self.num_blocks):\n",
    "\t\t\tself.message_passings.append(Sequential('x, edge_index', [(GCNConv(self.num_heads,self.num_heads), 'x, edge_index -> x'),nn.ReLU(inplace=True)]))\n",
    "\n",
    "\tdef forward(self, data):\n",
    "\n",
    "\t\tix_res = data.cpu().x[:,TYPE_INDEX].numpy()>0 #obtain node indices for the reservoirs\n",
    "\t\tix_edge = data.cpu().edge_index.numpy().T #obtain indices for the edges\n",
    "\t\tedge_index = ix_edge[np.logical_and(ix_edge[:,0] != np.where(ix_res),ix_edge[:,1] != np.where(ix_res)).T[:,0]] #remove the edges connecting to a reservoir\n",
    "\t\tedge_index = (edge_index[:, 0] < edge_index[:, 1]) #get unique edges\n",
    "\t\tix_edge = (ix_edge[:, 0] < ix_edge[:, 1]) #get unique edges\n",
    "\t\tx = data.x[~ix_res] #get nodal information at junctions\n",
    "\n",
    "\t\tA12 = self.A12.repeat(data.num_graphs,1,1)\n",
    "\t\tA21 = torch.transpose(A12,1,2)\n",
    "\t\tA10 = self.A10.repeat(data.num_graphs,1,1)\n",
    "\n",
    "\t\tq, H0, Q, l,d,c = torch.unsqueeze(x[:,1],dim=1).view(-1,self.num_heads,1).to(self.device), \\\n",
    "\t\t\t\t\t   torch.unsqueeze(torch.unsqueeze(data.x[data.cpu().x[:,TYPE_INDEX].numpy()>0,HEAD_INDEX],dim=1),dim=2).to(self.device), \\\n",
    "\t\t\t\t\t   torch.ones(self.num_flows).view(-1,self.num_flows,1).to(self.device), \\\n",
    "\t\t\t\t\t   data.edge_attr[ix_edge,LENGTH_INDEX].view(-1,self.num_flows,1).to(self.device), \\\n",
    "\t\t\t\t\t   data.edge_attr[ix_edge,DIAMETER_INDEX].view(-1,self.num_flows,1).to(self.device), \\\n",
    "\t\t\t\t\t   data.edge_attr[ix_edge,ROUGHNESS_INDEX].view(-1,self.num_flows,1).to(self.device)\n",
    "\n",
    "\t\tA10H0 = torch.bmm(A10,H0.double())\n",
    "\n",
    "\t\tfor i in range(self.num_blocks-1):\n",
    "\t\t\tr = torch.div(torch.mul(10.67,l),torch.mul(torch.pow(c,self.n),torch.pow(d,4.871)))\n",
    "\t\t\tD = torch.mul(self.n,torch.mul(r,torch.pow(torch.abs(Q),self.n-1))).flatten(start_dim=1)\n",
    "\t\t\tA11_Q = torch.div(1,torch.mul(self.n,D))\n",
    "\t\t\tD = torch.diag_embed(D)\n",
    "\t\t\tA11_Q = torch.diag_embed((A11_Q))\n",
    "\t\t\tF = torch.sum(torch.stack([torch.bmm(A21,Q.double()),q,-torch.bmm(torch.bmm(A21,torch.mul(D,A11_Q).double()),Q.double()),-torch.bmm(A21.double(),torch.bmm(D.double(),A10H0))]),dim=0)\n",
    "\t\t\tH = self.message_passings[i](x=torch.flatten(F,start_dim=1).T,edge_index = data.edge_index[:,edge_index]).view(-1,self.num_heads,1)\n",
    "\t\t\thid_Q = torch.mul(D,torch.sum(torch.stack([A11_Q,torch.bmm(A12,H),A10H0]),dim=0))\n",
    "\t\t\tQ = torch.sub(Q,hid_Q)\n",
    "\t\t\tif torch.any(H > 1000).item():\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\treturn self.out(torch.flatten(H,start_dim=1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working with FOS, network 1 of 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alber\\AppData\\Local\\Temp\\ipykernel_1036\\396142609.py:97: FutureWarning: incidence_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A12 = nx.incidence_matrix(to_networkx(graphs[0]), oriented=True).toarray().transpose()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnrollingGNN: training combination 1 of 4\t\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/39 [00:46<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [88], line 70\u001B[0m\n\u001B[0;32m     67\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(params\u001B[38;5;241m=\u001B[39mmodel\u001B[38;5;241m.\u001B[39mparameters(), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcfg[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madamParams\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     69\u001B[0m \u001B[38;5;66;03m# training\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m model, tra_losses, val_losses, elapsed_time, epochs \u001B[38;5;241m=\u001B[39m \u001B[43mtraining\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtra_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     71\u001B[0m \u001B[43m\t\t\t\t\t\t\t\t\t\t\t\t\t\t\u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreport_freq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     72\u001B[0m \u001B[43m\t\t\t\t\t\t\t\t\t\t\t\t\t   \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m\t\t\t\t\t\t\t\t\t\t\t\t\t   \u001B[49m\u001B[43mnormalization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mresults_folder\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mwdn\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43malgorithm\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m plot_loss(tra_losses,val_losses,\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresults_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwdn\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00malgorithm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/loss/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     75\u001B[0m plot_R2(model,val_loader,\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresults_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwdn\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00malgorithm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/R2/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mC:\\Code\\main_unrolling\\training\\train.py:171\u001B[0m, in \u001B[0;36mtraining\u001B[1;34m(model, optimizer, train_loader, val_loader, n_epochs, patience, report_freq, alpha, lr_rate, lr_epoch, normalization, device, path)\u001B[0m\n\u001B[0;32m    168\u001B[0m \u001B[38;5;66;03m# torch.autograd.set_detect_anomaly(True)\u001B[39;00m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m)):\n\u001B[0;32m    170\u001B[0m     \u001B[38;5;66;03m# Model training\u001B[39;00m\n\u001B[1;32m--> 171\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnormalization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    172\u001B[0m \u001B[43m                             \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    174\u001B[0m     \u001B[38;5;66;03m# Model validation\u001B[39;00m\n\u001B[0;32m    175\u001B[0m     val_loss, _, _, _, _, _ \u001B[38;5;241m=\u001B[39m testing(model, val_loader, alpha\u001B[38;5;241m=\u001B[39malpha, normalization\u001B[38;5;241m=\u001B[39mnormalization)\n",
      "File \u001B[1;32mC:\\Code\\main_unrolling\\training\\train.py:101\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[1;34m(model, loader, optimizer, alpha, normalization, device)\u001B[0m\n\u001B[0;32m     98\u001B[0m batch \u001B[38;5;241m=\u001B[39m batch\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m    100\u001B[0m \u001B[38;5;66;03m# Model prediction\u001B[39;00m\n\u001B[1;32m--> 101\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;66;03m# loss function = MSE if alpha=0\u001B[39;00m\n\u001B[0;32m    104\u001B[0m \u001B[38;5;66;03m# loss = smooth_loss(preds, batch, alpha=alpha)\u001B[39;00m\n\u001B[0;32m    105\u001B[0m loss \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mMSELoss()(preds, batch\u001B[38;5;241m.\u001B[39my)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Thesis\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[1;32mIn [87], line 52\u001B[0m, in \u001B[0;36mUnrollingGNN.forward\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     50\u001B[0m A11_Q \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdiag_embed((A11_Q))\n\u001B[0;32m     51\u001B[0m F \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(torch\u001B[38;5;241m.\u001B[39mstack([torch\u001B[38;5;241m.\u001B[39mbmm(A21,Q\u001B[38;5;241m.\u001B[39mdouble()),q,\u001B[38;5;241m-\u001B[39mtorch\u001B[38;5;241m.\u001B[39mbmm(torch\u001B[38;5;241m.\u001B[39mbmm(A21,torch\u001B[38;5;241m.\u001B[39mmul(D,A11_Q)\u001B[38;5;241m.\u001B[39mdouble()),Q\u001B[38;5;241m.\u001B[39mdouble()),\u001B[38;5;241m-\u001B[39mtorch\u001B[38;5;241m.\u001B[39mbmm(A21\u001B[38;5;241m.\u001B[39mdouble(),torch\u001B[38;5;241m.\u001B[39mbmm(D\u001B[38;5;241m.\u001B[39mdouble(),A10H0))]),dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 52\u001B[0m H \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241m.\u001B[39mmessage_passings[i](x\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mflatten(F,start_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mT,edge_index \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39medge_index[:,edge_index])\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads,\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     53\u001B[0m hid_Q \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmul(D,torch\u001B[38;5;241m.\u001B[39msum(torch\u001B[38;5;241m.\u001B[39mstack([A11_Q,torch\u001B[38;5;241m.\u001B[39mbmm(A12,H),A10H0]),dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m     54\u001B[0m Q \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msub(Q,hid_Q)\n",
      "Cell \u001B[1;32mIn [87], line 52\u001B[0m, in \u001B[0;36mUnrollingGNN.forward\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     50\u001B[0m A11_Q \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdiag_embed((A11_Q))\n\u001B[0;32m     51\u001B[0m F \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msum(torch\u001B[38;5;241m.\u001B[39mstack([torch\u001B[38;5;241m.\u001B[39mbmm(A21,Q\u001B[38;5;241m.\u001B[39mdouble()),q,\u001B[38;5;241m-\u001B[39mtorch\u001B[38;5;241m.\u001B[39mbmm(torch\u001B[38;5;241m.\u001B[39mbmm(A21,torch\u001B[38;5;241m.\u001B[39mmul(D,A11_Q)\u001B[38;5;241m.\u001B[39mdouble()),Q\u001B[38;5;241m.\u001B[39mdouble()),\u001B[38;5;241m-\u001B[39mtorch\u001B[38;5;241m.\u001B[39mbmm(A21\u001B[38;5;241m.\u001B[39mdouble(),torch\u001B[38;5;241m.\u001B[39mbmm(D\u001B[38;5;241m.\u001B[39mdouble(),A10H0))]),dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 52\u001B[0m H \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241m.\u001B[39mmessage_passings[i](x\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mflatten(F,start_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mT,edge_index \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39medge_index[:,edge_index])\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads,\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     53\u001B[0m hid_Q \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmul(D,torch\u001B[38;5;241m.\u001B[39msum(torch\u001B[38;5;241m.\u001B[39mstack([A11_Q,torch\u001B[38;5;241m.\u001B[39mbmm(A12,H),A10H0]),dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m     54\u001B[0m Q \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msub(Q,hid_Q)\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1179\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:620\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1095\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1053\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.2.4\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py:169\u001B[0m, in \u001B[0;36mstop\u001B[1;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[0;32m    167\u001B[0m     frame \u001B[38;5;241m=\u001B[39m suspend_jupyter(main_debugger, thread, frame, step_cmd)\n\u001B[0;32m    168\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m frame:\n\u001B[1;32m--> 169\u001B[0m         \u001B[43mmain_debugger\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    171\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.2.4\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1157\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1159\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1160\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.2.4\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1172\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1175\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1179\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for ix_wdn, wdn in enumerate(all_wdn_names):\n",
    "\tprint(f'\\nWorking with {wdn}, network {ix_wdn+1} of {len(all_wdn_names)}')\n",
    "\n",
    "\t# retrieve wntr data\n",
    "\ttra_database, val_database, tst_database = load_raw_dataset(wdn, data_folder)\n",
    "\t# reduce training data\n",
    "\t# tra_database = tra_database[:int(len(tra_database)*cfg['tra_prc'])]\n",
    "\tif cfg['tra_num'] < len(tra_database):\n",
    "\t\ttra_database = tra_database[:cfg['tra_num']]\n",
    "\n",
    "\t# remove PES anomaly\n",
    "\tif wdn == 'PES':\n",
    "\t\tif len(tra_database)>4468:\n",
    "\t\t\tdel tra_database[4468]\n",
    "\t\t\tprint('Removed PES anomaly')\n",
    "\t\t\tprint('Check',tra_database[4468].pressure.mean())\n",
    "\n",
    "\t# get GRAPH datasets    # later on we should change this and use normal scalers from scikit\n",
    "\ttra_dataset, A12_bar = create_dataset(tra_database)\n",
    "\ttra_dataset, _ = create_dataset(tra_database)\n",
    "\tval_dataset,_ = create_dataset(val_database)\n",
    "\ttst_dataset,_ = create_dataset(tst_database)\n",
    "\tnode_size, edge_size = tra_dataset[0].x.size(-1), tra_dataset[0].edge_attr.size(-1)\n",
    "\t# number of nodes\n",
    "\t# n_nodes=tra_dataset[0].x.shape[0]\n",
    "\tn_nodes=(1-tra_database[0].type_1H).numpy().sum() # remove reservoirs\n",
    "\t# dataloader\n",
    "\t# transform dataset for MLP\n",
    "\t# We begin with the MLP versions, when I want to add GNNs, check Riccardo's code\n",
    "\tA10,A12 = create_incidence_matrices(tra_dataset, A12_bar)\n",
    "\ttra_loader = torch_geometric.loader.DataLoader(tra_dataset, batch_size=batch_size,shuffle=True, pin_memory=True)\n",
    "\tval_loader = torch_geometric.loader.DataLoader(val_dataset, batch_size=batch_size,shuffle=False, pin_memory=True)\n",
    "\ttst_loader = torch_geometric.loader.DataLoader(tst_dataset, batch_size=batch_size,shuffle=False, pin_memory=True)\n",
    "\t# loop through different algorithms\n",
    "\tnode_size, edge_size = tra_dataset[0].x.size(-1), tra_dataset[0].edge_attr.size(-1)\n",
    "    # number of nodes\n",
    "    # n_nodes=tra_dataset[0].x.shape[0]\n",
    "\tn_nodes=(1-tra_database[0].type_1H).numpy().sum() # remove reservoirs\n",
    "\tn_epochs = n_nodes+edge_size\n",
    "\tfor algorithm in cfg['algorithms']:\n",
    "\n",
    "\t\thyperParams = cfg['hyperParams'][algorithm]\n",
    "\t\tall_combinations = ParameterGrid(hyperParams)\n",
    "\n",
    "\t\t# create results dataframe\n",
    "\t\tresults_df = pd.DataFrame(list(all_combinations))\n",
    "\t\tresults_df = pd.concat([results_df,\n",
    "\t\t\t\t\t\t\t\tpd.DataFrame(index=np.arange(len(all_combinations)),\n",
    "\t\t\t\t\t\t\t\t\t\t  columns=list(res_columns))],axis=1)\n",
    "\n",
    "\t\tfor i, combination in enumerate(all_combinations):\n",
    "\t\t\tprint(f'{algorithm}: training combination {i+1} of {len(all_combinations)}\\t',end='\\r',)\n",
    "\t\t\tcombination['num_outputs'] = n_nodes\n",
    "\t\t\tcombination['edge_features']=edge_size # all this ad-hoc stuff must be removed\n",
    "\t\t\tcombination['node_features']=node_size # (e.g., these two lines are needed to instantiate GNN properly)\n",
    "\t\t\tcombination['A12'] = A12\n",
    "\t\t\tcombination['A10'] = A10\n",
    "\n",
    "\t\t\twandb.config = combination\n",
    "\n",
    "\t\t\t# model creation\n",
    "\t\t\tmodel = getattr(sys.modules[__name__], algorithm)(**combination).double().to(device)\n",
    "\t\t\t# print(model)\n",
    "\t\t\ttotal_parameters = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "\t\t\t# model optimizer\n",
    "\t\t\toptimizer = optim.Adam(params=model.parameters(), **cfg['adamParams'])\n",
    "\n",
    "\t\t\t# training\n",
    "\t\t\tmodel, tra_losses, val_losses, elapsed_time, epochs = training(model, optimizer, tra_loader, val_loader,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tpatience=10, report_freq=0, n_epochs=n_epochs,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   alpha=alpha, lr_rate=2, lr_epoch=100,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   normalization=None, path = f'{results_folder}/{wdn}/{algorithm}/')\n",
    "\t\t\tplot_loss(tra_losses,val_losses,f'{results_folder}/{wdn}/{algorithm}/loss/{i}')\n",
    "\t\t\tplot_R2(model,val_loader,f'{results_folder}/{wdn}/{algorithm}/R2/{i}')\n",
    "\t\t\t# store training history and model\n",
    "\t\t\tpd.DataFrame(data = np.array([tra_losses, val_losses]).T).to_csv(\n",
    "\t\t\t\tf'{results_folder}/{wdn}/{algorithm}/hist/{i}.csv')\n",
    "\t\t\ttorch.save(model, f'{results_folder}/{wdn}/{algorithm}/models/{i}.csv')\n",
    "\n",
    "\t\t\t# compute and store predictions, compute r2 scores\n",
    "\t\t\tlosses = {}\n",
    "\t\t\tmax_losses = {}\n",
    "\t\t\tmin_losses = {}\n",
    "\t\t\tr2_scores = {}\n",
    "\t\t\tfor split, loader in zip(['training','validation','testing'],[tra_loader,val_loader,tst_loader]):\n",
    "\t\t\t\tlosses[split], max_losses[split], min_losses[split], pred, real, test_time = testing(model, loader)\n",
    "\t\t\t\tr2_scores[split] = r2_score(real, pred)\n",
    "\t\t\t\tif i == 0:\n",
    "\t\t\t\t\tpd.DataFrame(data=real.reshape(-1,n_nodes)).to_csv(\n",
    "\t\t\t\t\t\tf'{results_folder}/{wdn}/{algorithm}/pred/{split}/real.csv') # save real obs\n",
    "\t\t\t\tpd.DataFrame(data=pred.reshape(-1,n_nodes)).to_csv(\n",
    "\t\t\t\t\tf'{results_folder}/{wdn}/{algorithm}/pred/{split}/{i}.csv')\n",
    "\n",
    "\t\t\t# store results\n",
    "\t\t\tresults_df.loc[i,res_columns] = (losses['training'], losses['validation'], losses['testing'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t max_losses['training'], max_losses['validation'], max_losses['testing'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t min_losses['training'], min_losses['validation'], min_losses['testing'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t r2_scores['training'], r2_scores['validation'], r2_scores['testing'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t total_parameters, elapsed_time,test_time, epochs)\n",
    "\t\t# # save graph normalizer\n",
    "\t\t# with open(f'{results_folder}/{wdn}/{algorithm}/gn.pickle', 'wb') as handle:\n",
    "\t\t#     pickle.dump(gn, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\t\tresults_df.to_csv(f'{results_folder}/{wdn}/{algorithm}/results_{algorithm}.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.Dashboard import Dashboard\n",
    "from IPython.display import display\n",
    "\n",
    "_,_,_, pred, real, time = testing(model, val_loader)\n",
    "d = Dashboard(pd.DataFrame(real.reshape(-1,n_nodes)),pd.DataFrame(pred.reshape(-1,n_nodes)),to_networkx(val_dataset[0],node_attrs=['pos']))\n",
    "f = d.display_results()\n",
    "display(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "real = pd.read_csv(f'./experiments/unrolling_WDN0020/PES/MLP/pred/testing/real.csv').drop(columns=['Unnamed: 0'])\n",
    "mlp_pred = pd.read_csv(f'./experiments/unrolling_WDN0020/PES/MLP/pred/testing/6.csv').drop(columns=['Unnamed: 0'])\n",
    "unrolling_pred =  pd.read_csv(f'./experiments/unrolling_WDN0020/PES/UnrollingModel/pred/testing/1.csv').drop(columns=['Unnamed: 0'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "res = real.sub(mlp_pred).pow(2).sum(axis=0)\n",
    "tot = real.sub(mlp_pred.mean(axis=0)).pow(2).sum(axis=0)\n",
    "r2_mlp = 1 - res/tot\n",
    "res = real.sub(unrolling_pred).pow(2).sum(axis=0)\n",
    "tot = real.sub(unrolling_pred.mean(axis=0)).pow(2).sum(axis=0)\n",
    "r2_unrolling = 1 - res/tot\n",
    "r2s = pd.concat([r2_mlp,r2_unrolling],axis=1).rename(columns={0:'MLP',1:'AU-MLP'})\n",
    "fig, ax = plt.subplots()\n",
    "r2s.plot.box(ax=ax)\n",
    "ax.set_title(\"$R^2$ Scores Comparison for PES\")\n",
    "ax.set_ylabel('$R^2$ Score')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
