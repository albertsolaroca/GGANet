{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T15:07:33.282738400Z",
     "start_time": "2023-12-19T15:07:33.259774900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import wandb\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from utils.miscellaneous import read_config\n",
    "from utils.miscellaneous import create_folder_structure_MLPvsGNN\n",
    "from utils.miscellaneous import initalize_random_generators\n",
    "from utils.wandb_logger import save_response_graphs_in_ML_tracker\n",
    "from utils.normalization import *\n",
    "from utils.load import *\n",
    "\n",
    "from training.train import training\n",
    "from training.test import testing\n",
    "from training.models import * \n",
    "\n",
    "from utils.visualization import plot_R2, plot_loss\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse configuration file + initializations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T15:07:33.314156400Z",
     "start_time": "2023-12-19T15:07:33.287737700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folder: ./experiments/unrolling_WDN0057\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# read config files\n",
    "cfg = read_config(\"config_unrolling.yaml\")\n",
    "# create folder for result\n",
    "exp_name = cfg['exp_name']\n",
    "data_folder = cfg['data_folder']\n",
    "results_folder = create_folder_structure_MLPvsGNN(cfg, parent_folder='./experiments')\n",
    "\n",
    "all_wdn_names = cfg['network']\n",
    "initalize_random_generators(cfg, count=0)\n",
    "\n",
    "# initialize pytorch device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "#torch.set_num_threads(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T15:07:33.344507600Z",
     "start_time": "2023-12-19T15:07:33.314156400Z"
    }
   },
   "outputs": [],
   "source": [
    "# TO DO: at the moment I am not using the parsed values for batch size and num_epochs ;\n",
    "# I am not using alpha as well because the loss has no \"smoothness\" penalty (yet)\n",
    "batch_size = cfg['trainParams']['batch_size']\n",
    "num_epochs = cfg['trainParams']['num_epochs']\n",
    "res_columns = ['train_loss', 'valid_loss', 'test_loss', 'max_train_loss', 'max_valid_loss', 'max_test_loss',\n",
    "               'min_train_loss', 'min_valid_loss', 'min_test_loss', 'r2_train', 'r2_valid',\n",
    "               'r2_test', 'total_params', 'total_time', 'test_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "I will be Creating different models as follows:\n",
    "\n",
    "* A simple LSTM\n",
    "* An unrolled version of Heads and Flows, without static variables\n",
    "* An unrolled version with Heads, Flows and static variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working with KYPIPE Example 8 fix, network 1 of 1\n",
      "UnrollingModelQ: training combination 1 of 1\n",
      "\n",
      "Total number of parameters is 13931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/2000 [00:00<01:28, 22.42it/s]\n",
      "C:\\Uni\\Thesis\\Albert\\GGNet\\main_unrolling\\utils\\normalization.py:41: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(X) + self.min_ - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early Stopping\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 88\u001B[0m\n\u001B[0;32m     81\u001B[0m model, tra_losses, val_losses, elapsed_time \u001B[38;5;241m=\u001B[39m training(model, optimizer, tra_loader, val_loader,\n\u001B[0;32m     82\u001B[0m                                                        patience\u001B[38;5;241m=\u001B[39mpatience, report_freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[0;32m     83\u001B[0m                                                        n_epochs\u001B[38;5;241m=\u001B[39mnum_epochs,\n\u001B[0;32m     84\u001B[0m                                                        alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, lr_rate\u001B[38;5;241m=\u001B[39mlr_rate, lr_epoch\u001B[38;5;241m=\u001B[39mlr_epoch,\n\u001B[0;32m     85\u001B[0m                                                        normalization\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperiments\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     87\u001B[0m loss_plot \u001B[38;5;241m=\u001B[39m plot_loss(tra_losses, val_losses, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresults_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwdn\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00malgorithm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/loss/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m---> 88\u001B[0m R2_plot \u001B[38;5;241m=\u001B[39m \u001B[43mplot_R2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mresults_folder\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mwdn\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43malgorithm\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/R2/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mi\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnormalization\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgn\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     89\u001B[0m \u001B[38;5;66;03m# store training history and model\u001B[39;00m\n\u001B[0;32m     90\u001B[0m pd\u001B[38;5;241m.\u001B[39mDataFrame(data\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marray([tra_losses, val_losses])\u001B[38;5;241m.\u001B[39mT)\u001B[38;5;241m.\u001B[39mto_csv(\n\u001B[0;32m     91\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresults_folder\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mwdn\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00malgorithm\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/hist/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mC:\\Uni\\Thesis\\Albert\\GGNet\\main_unrolling\\utils\\visualization.py:92\u001B[0m, in \u001B[0;36mplot_R2\u001B[1;34m(model, loader, name, show, normalization)\u001B[0m\n\u001B[0;32m     89\u001B[0m         plt\u001B[38;5;241m.\u001B[39msavefig(name)\n\u001B[0;32m     90\u001B[0m         plt\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m---> 92\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mr2_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred\u001B[49m\u001B[43m)\u001B[49m, name\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     ):\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:989\u001B[0m, in \u001B[0;36mr2_score\u001B[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001B[0m\n\u001B[0;32m    848\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m    849\u001B[0m     {\n\u001B[0;32m    850\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    868\u001B[0m     force_finite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    869\u001B[0m ):\n\u001B[0;32m    870\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001B[39;00m\n\u001B[0;32m    871\u001B[0m \n\u001B[0;32m    872\u001B[0m \u001B[38;5;124;03m    Best possible score is 1.0 and it can be negative (because the\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    987\u001B[0m \u001B[38;5;124;03m    -inf\u001B[39;00m\n\u001B[0;32m    988\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 989\u001B[0m     y_type, y_true, y_pred, multioutput \u001B[38;5;241m=\u001B[39m \u001B[43m_check_reg_targets\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    990\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultioutput\u001B[49m\n\u001B[0;32m    991\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    992\u001B[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    994\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _num_samples(y_pred) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:101\u001B[0m, in \u001B[0;36m_check_reg_targets\u001B[1;34m(y_true, y_pred, multioutput, dtype)\u001B[0m\n\u001B[0;32m     99\u001B[0m check_consistent_length(y_true, y_pred)\n\u001B[0;32m    100\u001B[0m y_true \u001B[38;5;241m=\u001B[39m check_array(y_true, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m--> 101\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_true\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    104\u001B[0m     y_true \u001B[38;5;241m=\u001B[39m y_true\u001B[38;5;241m.\u001B[39mreshape((\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:959\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    953\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    954\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    955\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m    956\u001B[0m         )\n\u001B[0;32m    958\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m--> 959\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    960\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    961\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    962\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    963\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    964\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    966\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    967\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:124\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 124\u001B[0m \u001B[43m_assert_all_finite_element_wise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    131\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:173\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[0;32m    159\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    161\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    171\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    172\u001B[0m     )\n\u001B[1;32m--> 173\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[1;31mValueError\u001B[0m: Input contains infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "for ix_wdn, wdn in enumerate(all_wdn_names):\n",
    "    print(f'\\nWorking with {wdn}, network {ix_wdn + 1} of {len(all_wdn_names)}')\n",
    "\n",
    "    # retrieve wntr data\n",
    "    tra_database, val_database, tst_database = load_raw_dataset(wdn, data_folder)\n",
    "    # reduce training data\n",
    "    # tra_database = tra_database[:int(len(tra_database)*cfg['tra_prc'])]\n",
    "    if cfg['tra_num'] < len(tra_database):\n",
    "        tra_database = tra_database[:cfg['tra_num']]\n",
    "\n",
    "    # remove PES anomaly\n",
    "    if wdn == 'PES':\n",
    "        if len(tra_database) > 4468:\n",
    "            del tra_database[4468]\n",
    "            print('Removed PES anomaly')\n",
    "            print('Check', tra_database[4468].pressure.mean())\n",
    "\n",
    "    # get GRAPH datasets     \n",
    "    # later on we should change this and use normal scalers from scikit (something is off here)\n",
    "    tra_dataset, A12_bar = create_dataset(tra_database)\n",
    "    # number of nodes\n",
    "    junctions = (tra_database[0].node_type == JUNCTION_TYPE).numpy().sum()\n",
    "    tanks = (tra_database[0].node_type == TANK_TYPE).numpy().sum()\n",
    "    output_nodes = len(tra_dataset[0].y[0]) # remove reservoirs\n",
    "    gn = GraphNormalizer(junctions + tanks, output=['pressure', 'pump_flow'])\n",
    "    gn = gn.fit(tra_dataset)\n",
    "    # The normalization messed with the 1H_type since we want unique IDs\n",
    "    tra_dataset, _ = create_dataset(tra_database, normalizer=gn)\n",
    "    val_dataset, _ = create_dataset(val_database, normalizer=gn)\n",
    "    tst_dataset, _ = create_dataset(tst_database, normalizer=gn)\n",
    "    node_size, edge_size = tra_dataset[0].x.size(-1), tra_dataset[0].edge_attr.size(-1)\n",
    "    \n",
    "    # dataloader\n",
    "    # transform dataset for MLP\n",
    "    # We begin with the MLP versions, when I want to add GNNs, check Riccardo's code\n",
    "    A10, A12 = create_incidence_matrices(tra_dataset, A12_bar)\n",
    "    tra_dataset_MLP, num_inputs, indices = create_dataset_MLP_from_graphs(tra_dataset)\n",
    "    val_dataset_MLP = create_dataset_MLP_from_graphs(val_dataset)[0]\n",
    "    tst_dataset_MLP = create_dataset_MLP_from_graphs(tst_dataset)[0]\n",
    "    tra_loader = torch.utils.data.DataLoader(tra_dataset_MLP,\n",
    "                                             batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset_MLP,\n",
    "                                             batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    tst_loader = torch.utils.data.DataLoader(tst_dataset_MLP,\n",
    "                                             batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    # loop through different algorithms\n",
    "    for algorithm in cfg['algorithms']:\n",
    "        # Importing of configuration parameters\n",
    "        hyperParams = cfg['hyperParams'][algorithm]\n",
    "        all_combinations = ParameterGrid(hyperParams)\n",
    "\n",
    "        # create results dataframe\n",
    "        results_df = pd.DataFrame(list(all_combinations))\n",
    "        results_df = pd.concat([results_df,\n",
    "                                pd.DataFrame(index=np.arange(len(all_combinations)),\n",
    "                                             columns=list(res_columns))], axis=1)\n",
    "\n",
    "        for i, combination in enumerate(all_combinations):\n",
    "            # wandb.init(project=\"unrolling-epanet\", entity=\"mertz\")\n",
    "            print(f'{algorithm}: training combination {i + 1} of {len(all_combinations)}\\n')\n",
    "            \n",
    "            combination['indices'] = indices\n",
    "            combination['junctions'] = junctions\n",
    "            combination['num_outputs'] = output_nodes\n",
    "\n",
    "            # model creation\n",
    "            model = getattr(sys.modules[__name__], algorithm)(**combination).float().to(device)\n",
    "\n",
    "            # get combination dictionary to determine how are indices made\n",
    "            total_parameters = sum(p.numel() for p in model.parameters())\n",
    "            print(\"Total number of parameters is\", total_parameters)\n",
    "\n",
    "            # model optimizer\n",
    "            optimizer = optim.Adam(params=model.parameters(), betas=(0.9, 0.999), **cfg['adamParams'])\n",
    "\n",
    "            # training\n",
    "            patience = cfg['earlyStopping']['patience']\n",
    "            lr_rate = cfg['earlyStopping']['divisor']\n",
    "            lr_epoch = cfg['earlyStopping']['epoch_frequency']\n",
    "            train_config = {\"Patience\": patience, \"Learning Rate Divisor\": lr_rate, \"LR Epoch Division\": lr_epoch}\n",
    "            model, tra_losses, val_losses, elapsed_time = training(model, optimizer, tra_loader, val_loader,\n",
    "                                                                   patience=patience, report_freq=0,\n",
    "                                                                   n_epochs=num_epochs,\n",
    "                                                                   alpha=0, lr_rate=lr_rate, lr_epoch=lr_epoch,\n",
    "                                                                   normalization=None, path=\"experiments\")\n",
    "            \n",
    "            loss_plot = plot_loss(tra_losses, val_losses, f'{results_folder}/{wdn}/{algorithm}/loss/{i}')\n",
    "            R2_plot = plot_R2(model, val_loader, f'{results_folder}/{wdn}/{algorithm}/R2/{i}', normalization=gn)[1]\n",
    "            # store training history and model\n",
    "            pd.DataFrame(data=np.array([tra_losses, val_losses]).T).to_csv(\n",
    "                f'{results_folder}/{wdn}/{algorithm}/hist/{i}.csv')\n",
    "            torch.save(model, f'{results_folder}/{wdn}/{algorithm}/models/{i}.csv')\n",
    "\n",
    "            # compute and store predictions, compute r2 scores\n",
    "            losses = {}\n",
    "            max_losses = {}\n",
    "            min_losses = {}\n",
    "            r2_scores = {}\n",
    "            for split, loader in zip(['training', 'validation', 'testing'], [tra_loader, val_loader, tst_loader]):\n",
    "                losses[split], max_losses[split], min_losses[split], pred, real, test_time = testing(model, loader, normalization=gn)\n",
    "                r2_scores[split] = r2_score(real, pred)\n",
    "                if i == 0:\n",
    "                    pd.DataFrame(data=real.reshape(-1, output_nodes)).to_csv(\n",
    "                        f'{results_folder}/{wdn}/{algorithm}/pred/{split}/real.csv')  # save real obs\n",
    "                pd.DataFrame(data=pred.reshape(-1, output_nodes)).to_csv(\n",
    "                    f'{results_folder}/{wdn}/{algorithm}/pred/{split}/{i}.csv')\n",
    "\n",
    "            # log_wandb_data(combination, wdn, algorithm, len(tra_database), len(val_database), len(tst_database), cfg, train_config, loss_plot, R2_plot)\n",
    "            # store results\n",
    "            results_df.loc[i, res_columns] = (losses['training'], losses['validation'], losses['testing'],\n",
    "                                              max_losses['training'], max_losses['validation'], max_losses['testing'],\n",
    "                                              min_losses['training'], min_losses['validation'], min_losses['testing'],\n",
    "                                              r2_scores['training'], r2_scores['validation'], r2_scores['testing'],\n",
    "                                              total_parameters, elapsed_time, test_time)\n",
    "            \n",
    "        # Calculate dummy model    \n",
    "        # wandb.finish()\n",
    "        # save graph normalizer\n",
    "        # with open(f'{results_folder}/{wdn}/{algorithm}/gn.pickle', 'wb') as handle:\n",
    "        #     pickle.dump(gn, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        # \n",
    "        with open(f'{results_folder}/{wdn}/{algorithm}/model.pickle', 'wb') as handle:\n",
    "            torch.save(model, handle)\n",
    "        results_df.to_csv(f'{results_folder}/{wdn}/{algorithm}/results_{algorithm}.csv')\n",
    "        \n",
    "        print('Folder where model was saved is', results_folder)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T15:07:36.310313400Z",
     "start_time": "2023-12-19T15:07:33.366343800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils.Dashboard import Dashboard\n",
    "_, _, _, pred, real, timed = testing(model, tst_loader, normalization=gn)\n",
    "\n",
    "pred = gn.denormalize_multiple(pred, output_nodes)\n",
    "real = gn.denormalize_multiple(real, output_nodes)\n",
    "\n",
    "dummy = Dummy(junctions + tanks).evaluate(real)\n",
    "# Array below is created to ensure proper indexing of the nodes when displaying\n",
    "type_array = (tst_database[0].node_type == 0) | (tst_database[0].node_type == 2)\n",
    "d = Dashboard(pd.DataFrame(real[0:24, :]), pd.DataFrame(pred[0:24, :]),\n",
    "              to_networkx(tst_dataset[0], node_attrs=['pos', 'ID']), type_array)\n",
    "# f = d.display_results()\n",
    "\n",
    "for i in range(0, len(real[:]), 5):\n",
    "    plt.plot(real[0:100, i], label=\"Real\")\n",
    "    plt.plot(pred[0:100, i], label=\"Predicted\")\n",
    "    plt.plot(dummy[0:100, i], label=\"Dummy\")\n",
    "    plt.ylabel('Head')\n",
    "    plt.xlabel('Timestep')\n",
    "    \n",
    "    plt.legend()\n",
    "    # names = {0: 'Next to Reservoir', 1: 'Random Node', 6: 'Next to Tank', 26: 'Random Node', 36: 'Tank', 37: 'Pump'}\n",
    "    # plt.title(names[i])\n",
    "    # save_response_graphs_in_ML_tracker(real, pred, names[i], i)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plt.plot(real[0:100, 37], label=\"Real\")\n",
    "plt.plot(pred[0:100, 37], label=\"Predicted\")\n",
    "plt.plot(dummy[0:100, 37], label=\"Dummy\")\n",
    "plt.ylabel('LPS')\n",
    "plt.xlabel('Timestep')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(names[37])\n",
    "plt.show()\n",
    "plt.close()\n",
    "# save_response_graphs_in_ML_tracker(real, pred, names[i], i)\n",
    "# Create a table\n",
    "\n",
    "# Add Plotly figure as HTML file into Table\n",
    "table = wandb.Table(columns = [\"Figure\" + str(i)])\n",
    "# with open('./my_HTML_' + str(i) + '.html', 'r', encoding='utf-8') as file:\n",
    "#     html_content = file.read()\n",
    "# table.add_data(wandb.Html(html_content))\n",
    "# display(f)\n",
    "# wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-19T15:07:36.306282400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-19T15:07:36.308316500Z"
    }
   },
   "outputs": [],
   "source": [
    "gn.transform_array([1,2,3,2,1,0], 'pressure')\n",
    "gn.inverse_transform_array(gn.transform_array([1,2,3,2,1,0], 'pressure'), 'pressure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T15:07:36.314400100Z",
     "start_time": "2023-12-19T15:07:36.311368200Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def nse(observed, simulated):\n",
    "    \"\"\"\n",
    "    Calculate Nash-Sutcliffe Efficiency (NSE) for 2D tensors.\n",
    "\n",
    "    Args:\n",
    "    observed (torch.Tensor): Tensor containing observed values.\n",
    "    simulated (torch.Tensor): Tensor containing simulated values.\n",
    "\n",
    "    Returns:\n",
    "    NSE (float): Nash-Sutcliffe Efficiency value.\n",
    "    \"\"\"\n",
    "    assert observed.shape == simulated.shape, \"Input tensors must have the same shape.\"\n",
    "    \n",
    "    numerator = torch.sum((observed - simulated) ** 2)\n",
    "    denominator = torch.sum((observed - torch.mean(observed)) ** 2)\n",
    "    \n",
    "    nse = 1 - (numerator / denominator)\n",
    "    return nse.item()\n",
    "\n",
    "dummy_score = r2_score(real, dummy, multioutput='variance_weighted')\n",
    "model_score = r2_score(real, pred, multioutput='variance_weighted')\n",
    "print(\"R2-values \\n\", \"Dummy:\", dummy_score, \"\\n Model\", model_score)\n",
    "\n",
    "dummy_score = mean_absolute_error(real, dummy)\n",
    "model_score = mean_absolute_error(real, pred)\n",
    "print(\"MAE-values \\n\", \"Dummy:\", dummy_score, \"\\n Model\", model_score)\n",
    "\n",
    "dummy_score = mean_squared_error(real, dummy)\n",
    "model_score = mean_squared_error(real, pred)\n",
    "print(\"MSE-values \\n\", \"Dummy:\", dummy_score, \"\\n Model\", model_score)\n",
    "\n",
    "\n",
    "dummy_score = mean_squared_error(real, dummy, squared=False)\n",
    "model_score = mean_squared_error(real, pred, squared=False)\n",
    "print(\"RMSE-values \\n\", \"Dummy:\", dummy_score, \"\\n Model\", model_score)\n",
    "\n",
    "dummy_score = nse(real, dummy)\n",
    "model_score = nse(real, pred)\n",
    "print(\"NSE-values \\n\", \"Dummy:\", dummy_score, \"\\n Model\", model_score)\n",
    "\n",
    "dummy_scores = []\n",
    "model_scores = []\n",
    "\n",
    "for i in range(38):\n",
    "    dummy_score = nse(real[:, i], dummy[:, i])\n",
    "    model_score = nse(real[:, i], pred[:, i])\n",
    "    dummy_scores.append(dummy_score)\n",
    "    model_scores.append(model_score)\n",
    "    \n",
    "    print(\"NSE-values\", dummy_score, model_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-19T15:07:36.313409700Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "with open(f'{results_folder}/{wdn}/{algorithm}/model.pickle', 'rb') as handle:\n",
    "    loaded_model = torch.load(handle)\n",
    "    loaded_model.eval()\n",
    "    \n",
    "\n",
    "# print(len(tra_dataset_MLP), len(tra_dataset_MLP[0]), len(tra_dataset_MLP[0][0]))\n",
    "input = tra_dataset_MLP[0][0].unsqueeze(0).to(device)\n",
    "print(input.shape)\n",
    "\n",
    "start_time = time.time_ns()\n",
    "print(start_time)\n",
    "for batch in tra_loader:\n",
    "    input = batch[0].to(device)\n",
    "    output = model(input)\n",
    "\n",
    "end_time = time.time_ns()\n",
    "print(end_time)\n",
    "\n",
    "print(f\"Simulation time: {end_time - start_time}\")\n",
    "\n",
    "output = output.detach().cpu().numpy()\n",
    "real = gn.inverse_transform_array(output, 'pressure')\n",
    "print(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-19T15:07:36.314400100Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re\n",
    "\n",
    "# Directory path where you want to search\n",
    "directory_path = \"./experiments\"\n",
    "\n",
    "# Get a list of all subdirectories in the specified directory\n",
    "subdirectories = [d for d in os.listdir(directory_path) if os.path.isdir(os.path.join(directory_path, d))]\n",
    "\n",
    "# Filter and extract the numbers from directory names\n",
    "wdn_numbers = []\n",
    "for subdir in subdirectories:\n",
    "    match = re.match(r'unrolling_WDN(\\d{4})', subdir)\n",
    "    if match:\n",
    "        wdn_numbers.append(int(match.group(1)))\n",
    "\n",
    "# Find the latest WDN number\n",
    "latest_wdn_number = None\n",
    "if wdn_numbers:\n",
    "    latest_wdn_number = max(wdn_numbers)\n",
    "    latest_wdn_folder = f'unrolling_WDN{latest_wdn_number:04d}'\n",
    "    print(f\"The latest WDN folder is: {latest_wdn_folder}\")\n",
    "else:\n",
    "    print(\"No WDN folders found in the specified directory.\")\n",
    "\n",
    "if latest_wdn_folder is not None:\n",
    "    real = pd.read_csv(f'./experiments/unrolling_WDN{latest_wdn_number:04d}/FOS_tank/LSTM/pred/testing/real.csv').drop(\n",
    "        columns=['Unnamed: 0'])\n",
    "    lstm_pred = pd.read_csv(\n",
    "        f'./experiments/unrolling_WDN{latest_wdn_number:04d}/FOS_tank/LSTM/pred/testing/0.csv').drop(\n",
    "        columns=['Unnamed: 0'])\n",
    "    unrolling_pred = pd.read_csv(\n",
    "        f'./experiments/unrolling_WDN{latest_wdn_number:04d}/FOS_tank/BaselineUnrolling/pred/testing/0.csv').drop(\n",
    "        columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-19T15:07:36.316456500Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Not sure if below makes sense since we now have an extra dimension\n",
    "res = real.sub(lstm_pred).pow(2).sum(axis=0)\n",
    "tot = real.sub(lstm_pred.mean(axis=0)).pow(2).sum(axis=0)\n",
    "r2_lstm = 1 - res / tot\n",
    "res = real.sub(unrolling_pred).pow(2).sum(axis=0)\n",
    "tot = real.sub(unrolling_pred.mean(axis=0)).pow(2).sum(axis=0)\n",
    "r2_unrolling = 1 - res / tot\n",
    "r2s = pd.concat([r2_lstm, r2_unrolling], axis=1).rename(columns={0: 'LSTM', 1: 'Base-U'})\n",
    "fig, ax = plt.subplots()\n",
    "r2s.plot.box(ax=ax)\n",
    "ax.set_title(\"$R^2$ Scores Comparison for PES\")\n",
    "ax.set_ylabel('$R^2$ Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T15:07:36.323588600Z",
     "start_time": "2023-12-19T15:07:36.319585900Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load(f'{results_folder}/{wdn}/{algorithm}/model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-19T15:07:36.320539Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
